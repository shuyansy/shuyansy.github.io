<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yan Shu (舒言)</title>

    <meta name="author" content="Yan Shu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Yan Shu (舒言)
                </p>
                <p>I'm an incoming PhD candidate at the University of Trento. I will join <a href="https://mhug.disi.unitn.it/#/">MHUG Group </a> supervised by <a href="https://paolorota.github.io/">Paolo Rota </a> and <a href="https://disi.unitn.it/~sebe/">Nicu Sebe </a>.
                </p>
                <p>
                  Previously, I was a research intern in <a href="https://2024.baai.ac.cn/">Beijing Academy of Artificial Intelligence (BAAI) </a>  supervised by <a href="https://www.bozhao.me/">Bo Zhao </a> and <a href="https://scholar.google.com.hk/citations?user=k2SF4M0AAAAJ&hl=en">Zheng Liu </a>.
                </p>
		<p>
                  Before that, I got Master`s degree from Harbin Institute of Technology, supervised by  <a href="https://scholar.google.com/citations?hl=zh-CN&user=mpwos7UAAAAJ&view_op=list_works&sortby=pubdate">Shaohui Liu</a>. I also worked as research assistant in Institute of Information Engineering, Chinese Academy of Sciences, advised by <a href="https://scholar.google.com/citations?hl=zh-CN&user=FNfBHg8AAAAJ">Yu Zhou</a>  
                </p>
                <p style="text-align:center">
                  <a href="shuyan9812@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=qLu1W08AAAAJ&hl=zh-CN">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/YanShu_hit">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/shuyansy">Github</a> &nbsp;/&nbsp;
		  <a href="https://www.xiaohongshu.com/user/profile/5b51b0dee8ac2b3d2b93e666">小红书</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/shuyan.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/shuyan.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, multimodal learning, video understanding and OCR. Below are some selected publications. (* indicates equal contribution.)
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



    <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
                <img src='images/videoxl.png' width="180" height="auto" style="margin-top: 20px;">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/VectorSpaceLab/Video-XL">
                <span class="papertitle">Video-XL: Extra-Long Vision Language Model for Hour-Scale Video Understanding</span>
            </a>
            <br>
            <a><strong>Yan Shu</strong></a>,
            <a>Peitian Zhang</a>, 
            <a>Zheng Liu</a>,
            <a>Minghao Qin</a>, 
            <a>Junjie Zhou</a>, 
            <a>Tiejun Huang</a>,
            <a>Bo Zhao</a>
            <br>
            <em>Arxiv</em>, 2024 &nbsp
            <br>
            <a href="https://github.com/VectorSpaceLab/Video-XL">project page</a> /
            <a href="https://arxiv.org/pdf/2409.14485">arXiv</a>
            <p></p>
            <p>First-ever hour-scale video understanding models.</p>
        </td>
    </tr>

    <tr style="margin-bottom: 40px;"> 
        <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
                <img src='images/mlvu.png' width="180" height="auto" style="margin-top: 20px;">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/JUNJIE99/MLVU">
                <span class="papertitle">MLVU: Multi-task Long Video Understanding Benchmark</span>
            </a>
            <br>
            <a>Junjie Zhou*</a>,
            <a><strong>Yan Shu*</strong></a>,
            <a>Bo Zhao*</a>,
            <a>Boya Wu</a>,
            <a>Shitao Xiao</a>, 
            <a>Xi Yang</a>, 
            <a>Yongping Xiong</a>,
            <a>Bo Zhang</a>,
            <a>Tiejun Huang</a>,
            <a>Zheng Liu</a>
            <br>
            <em>Arxiv</em>, 2024 &nbsp
            <br>
            <a href="https://github.com/JUNJIE99/MLVU">project page</a> /
            <a href="https://arxiv.org/abs/2406.04264">arXiv</a>
            <p></p>
            <p>First-ever comprehensive long video benchmark.</p>
        </td>
    </tr>

     <tr style="margin-bottom: 40px;"> 
        <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
                <img src='images/textctrl.png' width="180" height="auto" style="margin-top: 20px;">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/weichaozeng/TextCtrl">
                <span class="papertitle">TextCtrl: Diffusion-based Scene Text Editing with Prior Guidance Control</span>
            </a>
            <br>
            <a>Weichao Zeng</a>,
            <a><strong>Yan Shu</strong></a>,
            <a>Zhenhang Li</a>,
            <a>Dongbao Yang</a>,
            <a>Yu Zhou</a>
            <br>
            <em>NeurIPS</em>, 2024 &nbsp 
            <font color="red"><strong>(Spotlight)</strong></font>
            <br>
            <a href="https://github.com/weichaozeng/TextCtrl">project page</a> /
            <a href="https://arxiv.org/abs/2410.10133">arXiv</a>
            <p></p>
            <p>A diffusion-based scene text editing model as well as a real-world scene text editing benchmark.</p>
        </td>
    </tr>


		  
<tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
                <img src='images/blending.png' width="180" height="auto" style="margin-top: 20px;">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/Zhenhang-Li/GlyphOnly">
                <span class="papertitle">First Creating Backgrounds Then Rendering Texts: A New Paradigm for Visual Text Blending</span>
            </a>
            <br>
             <a>Zhenhang Li</a>,
            <a><strong>Yan Shu</strong></a>,
	    <a>Weichao Zeng</a>
            <a>Dongbao Yang</a>,
            <a>Yu Zhou</a>
            <br>
            <em>ECAI</em>, 2024 &nbsp 
            <br>
            <a href="https://github.com/Zhenhang-Li/GlyphOnly">project page</a> /
            <a href="https://arxiv.org/pdf/2410.10168">arXiv</a>
            <p></p>
            <p>A diffusion-based scene text generation model as well as a synthetic scene text detection dataset.</p>
        </td>
    </tr>

		  
<tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
                <img src='images/clifvqa.png' width="180" height="auto" style="margin-top: 20px;">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="">
                <span class="papertitle">CLiF-VQA: Enhancing Video Quality Assessment by Incorporating High-Level Semantic Information related to Human Feelings</span>
            </a>
            <br>
             <a>Yachun Mi</a>,
            <a><strong>Yan Shu</strong></a>,
	    <a>Yu Li</a>
            <a>Chen Hui</a>,
            <a>Puchao Zhou</a>,
	<a>Shaohui Liu</a>
            <br>
            <em>ACM MM</em>, 2024 &nbsp 
            <br>
            <a href="">project page</a> /
            <a href="https://arxiv.org/pdf/2311.07090">arXiv</a>
            <p></p>
            <p>Video quality assessment framework based on CLIP.</p>
        </td>
    </tr>



<tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
                <img src='images/survey.png' width="180" height="auto" style="margin-top: 20px;">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/shuyansy/Survey-of-Visual-Text-Processing">
                <span class="papertitle">Visual Text Meets Low-level Vision: A Comprehensive Survey on Visual Text Processing</span>
            </a>
            <br>
            <a><strong>Yan Shu</strong></a>,
	    <a>Weichao Zeng</a>
            <a>Zhenhang Li</a>,
            <a>Fangmin Zhao</a>,
	<a>Yu Zhou</a>
            <br>
            <em>Arxiv</em>, 2024 &nbsp 
            <br>
            <a href="https://github.com/shuyansy/Survey-of-Visual-Text-Processing">project page</a> /
            <a href="https://arxiv.org/pdf/2402.03082">arXiv</a>
            <p></p>
            <p>Survey on low-level scene text processing methods.</p>
        </td>
    </tr>


		  <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
                <img src='images/parser.png' width="180" height="auto" style="margin-top: 20px;">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/shuyansy/Efficient-Ambiguous-Text-Detector">
                <span class="papertitle">Perceiving Ambiguity and Semantics without Recognition: An Efficient and Effective Ambiguous Scene Text Detector</span>
            </a>
            <br>
            <a><strong>Yan Shu</strong></a>,
	    <a>Wei Wang</a>,
		<a>Yu Zhou</a>,
            <a>Shaohui Liu</a>,
		<a>Aoting Zhang</a>,
            <a>Dongbao Yang</a>,
	<a>Weiping Wang</a>
            <br>
            <em>ACM MM</em>, 2023 &nbsp 
		<font color="red"><strong>(Oral)</strong></font>
            <br>
            <a href="https://github.com/shuyansy/Efficient-Ambiguous-Text-Detector">project page</a> /
            <a href="https://dl.acm.org/doi/pdf/10.1145/3581783.3612383">arXiv</a>
            <p></p>
            <p>A model designed for ambiguous scene text detection.</p>
        </td>
    </tr>




    
    
      
            
            














            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/fast_texture.jpg" alt="fast-texture" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1rc05NatkQVmUDlGCAYcHSrvAzTpU9knT/view?usp=sharing">
                  <span class="papertitle">Discovering Efficiency in Coarse-To-Fine Texture Classification</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>Technical Report</em>, 2010
                <br>
                <a href="data/BarronTR2010.bib">bibtex</a>
                <p>A model and feature representation that allows for sub-linear coarse-to-fine semantic segmentation.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/prl.jpg" alt="prl" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/13rVuJpcytRdLYCnKpq46g7B7IzSrPQ2P/view?usp=sharing">
                  <span class="papertitle">Parallelizing Reinforcement Learning</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/~dsg/">Dave Golland</a>, <a href="http://www.cs.berkeley.edu/~nickjhay/">Nicholas J. Hay</a>
                <br>
                <em>Technical Report</em>, 2009
                <br>
                <a href="data/BarronPRL2009.bib">bibtex</a>
                <p>Markov Decision Problems which lie in a low-dimensional latent space can be decomposed, allowing modified RL algorithms to run orders of magnitude faster in parallel.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/bd_promo.jpg" alt="blind-date" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1PQjzKgFcrAesMIDJr-WDlCwuGUxZJZwO/view?usp=sharing">
                  <span class="papertitle">Blind Date: Using Proper Motions to Determine the Ages of Historical Images</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>
                <br>
                <em>The Astronomical Journal</em>, 136, 2008
                <p>Using the relative motions of stars we can accurately estimate the date of origin of historical astronomical images.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/clean_promo.jpg" alt="clean-usnob" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://drive.google.com/file/d/1YvRx-4hrZoCk-nl6OgVJZlHAqOiN5hWq/view?usp=sharing">
                  <span class="papertitle">Cleaning the USNO-B Catalog Through Automatic Detection of Optical Artifacts</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://stumm.ca/">Christopher Stumm</a>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>
                <br>
                <em>The Astronomical Journal</em>, 135, 2008
                <p>We use computer vision techniques to identify and remove diffraction spikes and reflection halos in the USNO-B Catalog.</p>
                <p>In use at <a href="http://www.astrometry.net">Astrometry.net</a></p>
              </td>
            </tr>

          </tbody></table>

          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
              <td width="75%" valign="center">
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/cs188.jpg" alt="cs188">
              </td>
              <td width="75%" valign="center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            

            <tr>
              <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                <h2>Basically <br> Blog Posts</h2>
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>
            
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
